{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1qh-R-XVgwzEbUZvwSes4g76-tzYfoMKr","timestamp":1667859656032}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ml58PJ9UDwRk"},"source":["**Principal Component Analysis**\n","\n","You will implement dimensionality reduction with PCA.  \n","\n","1). Read iris_dataset.csv (4 features, hence 4 PCs)\n","\n","2). Find the principal components\n","\n","3). Recontruct the dataset (X_hat)\n","\n","4). Determine the accuracy of X_hat for 1 PC and 4 PCs using LDA classifier (provided below)\n"]},{"cell_type":"code","metadata":{"id":"b3DA-QxT0O6X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670272774378,"user_tz":480,"elapsed":966,"user":{"displayName":"Andrew San Juan","userId":"13369662966910258698"}},"outputId":"6656aa6c-fe9a-42d0-a1d0-2b7cfc337c7e"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from numpy import linalg as LA\n","\n","\n","# Load data - 150 observations, 4 features, 3 classes, \n","df = pd.read_csv(\"iris_dataset.csv\", header=None)\n","print(df.describe())\n","data = df.values"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["                0           1           2           3           4\n","count  150.000000  150.000000  150.000000  150.000000  150.000000\n","mean     5.843333    3.057333    3.758000    1.199333    2.000000\n","std      0.828066    0.435866    1.765298    0.762238    0.819232\n","min      4.300000    2.000000    1.000000    0.100000    1.000000\n","25%      5.100000    2.800000    1.600000    0.300000    1.000000\n","50%      5.800000    3.000000    4.350000    1.300000    2.000000\n","75%      6.400000    3.300000    5.100000    1.800000    3.000000\n","max      7.900000    4.400000    6.900000    2.500000    3.000000\n"]}]},{"cell_type":"code","metadata":{"id":"9J_I64r12CK1","executionInfo":{"status":"ok","timestamp":1670272774378,"user_tz":480,"elapsed":7,"user":{"displayName":"Andrew San Juan","userId":"13369662966910258698"}}},"source":["## Setup\n","\n","# Shuffle data randomly\n","shuffled_data = data;\n","np.random.shuffle(shuffled_data)\n","X = shuffled_data[:,0:4]  # 150x4\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"g3llQ6-RP00N","executionInfo":{"status":"ok","timestamp":1670272774379,"user_tz":480,"elapsed":6,"user":{"displayName":"Andrew San Juan","userId":"13369662966910258698"}}},"source":["def evaluate_performance(Xhat, Num_PC, recon_error):\n","  '''\n","    Inputs:\n","      Xhat : reconstructed data set, size 150x4\n","      Num_PC : number of PCs to be used for reconstruction\n","      recon_error : reconstruction error\n","  '''\n","  \n","  ##################################\n","  # Evaluate performance using LDA #\n","  ##################################\n","  \n","  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","  from sklearn.model_selection import cross_val_score\n","\n","  no_dim = Num_PC  # number of dimensions\n","  #X_train = X[:,0:no_dim]           # original dataset\n","  X_train = Xhat[:,0:Num_PC]        # dimensionally reduced dataset\n","  y_train = data[:,4]\n","\n","  model_mean_scores = []\n","  model = LinearDiscriminantAnalysis().fit(X_train, y_train)\n","  scores = cross_val_score(model, X_train, y_train, cv=10)\n","  model_mean_scores.append(np.mean(scores))\n","\n","  # Reconstruction error\n","  print('Reconstruction error = {0:0.6f} with {1:1d} PCs, average accuracy = {2:0.4f}'\n","     .format(recon_error, Num_PC, model_mean_scores[0]))"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-L8WvJIAKeY","executionInfo":{"status":"ok","timestamp":1670272774379,"user_tz":480,"elapsed":4,"user":{"displayName":"Andrew San Juan","userId":"13369662966910258698"}}},"source":["def create_pc(X, Num_PC):\n","  '''\n","    Inputs: \n","      X : original data set, size 150x4\n","      Num_PC : number of PC's to be used to recover Xhat\n","    Outputs:\n","      PC : principal components, size 150x4\n","      Xhat : reconstructed data set, size 150x4\n","      recon_error : reconstruction error\n","  '''\n","\n","  ##################################\n","  ## Create Principal Components\n","  ##################################\n","\n","  ## Zero out mean of data\n","  # Hint: use np.mean with axis=0\n","  # Your code goes here ...\n","  X_mean = np.copy(X)\n","  X_mean[:]=np.mean(X_mean,axis=0)\n","  X_mean[:,0] = 0\n","\n","  ## Find the covariance matrix (4x4)\n","  # Hint: use np.cov and np.transpose\n","  # Your code goes here ...\n","  X_cov = np.subtract(X,X_mean)\n","  X_cov = np.cov(np.transpose(X_cov))\n","\n","  ## Apply eigendecomposition to the covariance matrix\n","  ## Eigenvalues w (4x1); eigenvector V (4x4)\n","  # Hint: w,V = LA.eig(...) \n","  #   where V is the eigenmatrix (4x4) and w is the eigenvalues(4x1)\n","  # Your code goes here ...\n","  w,V = LA.eig(X_cov)\n","\n","\n","  ## Compute principal components\n","  ## PC (150x4)\n","  # Hint: use np.matmul\n","  # Your code goes here ...\n","  PC = np.matmul(np.subtract(X,X_mean),V)\n","\n","\n","  ########################################################\n","  # Reconstruct X_hat & compute the reconstruction error\n","  ########################################################\n","  ## Compute Xhat (150x4)\n","  ## Num_PC : number of PC's used to reconstruct X_hat\n","  # Hint: use np.matmul, np.transpose\n","  # Your code goes here ...\n","  if(Num_PC == 1):\n","    X_hat = np.add(X_mean,PC)\n","  else:\n","    X_hat = np.add(X_mean,np.matmul(PC,np.transpose(V)))\n","\n","\n","  # Reconstruction error\n","  #    (l2norm(X) - l2norm(Xhat)) / l2norm(X)\n","  # Hint: use np.linalg.norm\n","  # Your code goes here ...\n","\n","  recon_err = (np.linalg.norm(X) - np.linalg.norm(X_hat)) / np.linalg.norm(X)\n","\n","  return PC, X_hat, recon_err"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"5wh_U_JnLhjy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670272777069,"user_tz":480,"elapsed":2694,"user":{"displayName":"Andrew San Juan","userId":"13369662966910258698"}},"outputId":"a20deaa9-e05a-4397-8539-ec0cf952cb08"},"source":["PC, X_hat, recon_err = create_pc(X,1)\n","evaluate_performance(X_hat, 1, recon_err)\n","\n","PC, X_hat, recon_err = create_pc(X,4)\n","evaluate_performance(X_hat, 4, recon_err)\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Reconstruction error = 0.453473 with 1 PCs, average accuracy = 0.9267\n","Reconstruction error = -0.000000 with 4 PCs, average accuracy = 0.9800\n"]}]}]}